{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados preparados\n",
    "x_treino = np.load('x_treino.npy')  \n",
    "y_treino = np.load('y_treino.npy')  \n",
    "z_treino = np.load('z_treino.npy')\n",
    "\n",
    "x_validacao = np.load('x_validacao.npy')  \n",
    "y_validacao = np.load('y_validacao.npy')  \n",
    "z_validacao = np.load('z_validacao.npy')\n",
    "\n",
    "x_teste = np.load('x_teste.npy')  \n",
    "y_teste = np.load('y_teste.npy')  \n",
    "z_teste = np.load('z_teste.npy')\n",
    "\n",
    "print(np.shape(x_treino))\n",
    "print(np.shape(x_validacao))\n",
    "print(np.shape(x_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_matriz_confusao(respostas, predicoes, rotulos):\n",
    "    cm = confusion_matrix(respostas, predicoes)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=rotulos, yticklabels=rotulos)\n",
    "    plt.xlabel('Rótulos previstos')\n",
    "    plt.ylabel('Rótulos verdadeiros')\n",
    "    plt.title('Matriz de confusão')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95) \n",
    "x_treino_pca = pca.fit_transform(x_treino)\n",
    "x_validacao_pca = pca.transform(x_validacao)\n",
    "x_teste_pca = pca.transform(x_teste)\n",
    "\n",
    "print(\"TREINAMENTO\")\n",
    "print(f\"Dimensões originais: {np.shape(x_treino)}\")\n",
    "print(f\"Dimensões após PCA: {np.shape(x_treino_pca)}\")\n",
    "print(\"VALIDAÇÃO\")\n",
    "print(f\"Dimensões originais: {np.shape(x_validacao)}\")\n",
    "print(f\"Dimensões após PCA: {np.shape(x_validacao_pca)}\")\n",
    "print(\"TESTE\")\n",
    "print(f\"Dimensões originais: {np.shape(x_teste)}\")\n",
    "print(f\"Dimensões após PCA: {np.shape(x_teste_pca)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP padrão\n",
    "- hidden_layer_sizes: (100,)\n",
    "- activation: 'relu'\n",
    "- solver: 'adam'\n",
    "- alpha: 0.0001\n",
    "- batch_size: 'auto'\n",
    "- learning_rate: \"constant\"\n",
    "- learning_rate_init: 0.001\n",
    "- power_t: 0.5\n",
    "- max_iter: 200\n",
    "- shuffle: True\n",
    "- random_state: None\n",
    "- tol: 1e-4\n",
    "- verbose: False\n",
    "- warm_state: False\n",
    "- momentum: 0.9\n",
    "- nesterovs_momentum: True\n",
    "- early_stopping: False\n",
    "- validation_fraction: 0.1\n",
    "- beta_1: 0.9\n",
    "- beta_2: 0.999\n",
    "- epsilon: 1e-8\n",
    "- n_iter_no_change: 10\n",
    "- max_fun: 15000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_padrao = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    mlp_padrao, x_treino_pca, y_treino, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Acurácia no Treinamento', marker='o', color='blue')\n",
    "plt.plot(train_sizes, test_mean, label='Acurácia no Teste', marker='o', color='orange')\n",
    "plt.xlabel('Tamanho do Conjunto de Treinamento')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.title('Curvas de Aprendizado')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_padrao.fit(x_treino_pca, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao_validacao_padrao = mlp_padrao.predict(x_validacao_pca)\n",
    "treino_acuracia_padrao = accuracy_score(y_validacao, predicao_validacao_padrao)\n",
    "print(\"Acurácia (modelo inicial):\", treino_acuracia_padrao)\n",
    "print(\"Relatório de Classificação (modelo inicial):\\n\", classification_report(y_validacao, predicao_validacao_padrao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao_teste_padrao = mlp_padrao.predict(x_teste_pca)\n",
    "teste_acuracia_padrao = accuracy_score(y_teste, predicao_teste_padrao)\n",
    "print(\"Acurácia (modelo inicial):\", teste_acuracia_padrao)\n",
    "print(\"Relatório de Classificação (modelo inicial):\\n\", classification_report(y_teste, predicao_teste_padrao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para gerar a matriz de confusão.\n",
    "letras = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"I\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"Y\"]\n",
    "y_prob_teste = mlp_padrao.predict_proba(x_teste_pca)\n",
    "\n",
    "plotar_matriz_confusao(y_teste, predicao_teste_padrao, letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_ruidosa = x_teste_pca + np.random.normal(0, 0.1, x_teste_pca.shape)\n",
    "x_teste_ruidosa = np.clip(x_teste_ruidosa, 0, 1)\n",
    "\n",
    "y_pred_ruidosa = mlp_padrao.predict(x_teste_ruidosa)\n",
    "teste_acuracia_padrao = accuracy_score(y_teste, y_pred_ruidosa)\n",
    "\n",
    "print(\"Acurácia:\", teste_acuracia_padrao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP otimizado: \n",
    "- activation: 'relu'\n",
    "- hidden_layer_sizes: (100,)\n",
    "- solver: 'adam'\n",
    "- max_iter: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,)],\n",
    "    'max_iter': [50, 100, 200],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "}\n",
    "grid_search = GridSearchCV(MLPClassifier(random_state=42), param_grid, scoring='accuracy', cv=2, verbose=2)\n",
    "grid_search.fit(x_treino_pca, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid_search.best_estimator_\n",
    "\n",
    "print(\"Melhores parâmetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Melhor score encontrado:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_otimizado = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, random_state=42, solver='adam', activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    mlp_otimizado, x_treino_pca, y_treino, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Acurácia no Treinamento', marker='o', color='blue')\n",
    "plt.plot(train_sizes, test_mean, label='Acurácia no Teste', marker='o', color='orange')\n",
    "plt.xlabel('Tamanho do Conjunto de Treinamento')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.title('Curvas de Aprendizado')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_otimizado.fit(x_treino_pca, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao_validacao_otimizado = mlp_otimizado.predict(x_validacao_pca)\n",
    "treino_acuracia_otimizado = accuracy_score(y_validacao, predicao_validacao_otimizado)\n",
    "print(\"Acurácia (modelo inicial):\", treino_acuracia_otimizado)\n",
    "print(\"Relatório de Classificação (modelo inicial):\\n\", classification_report(y_validacao, predicao_validacao_otimizado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao_teste_otimizado = mlp_otimizado.predict(x_teste_pca)\n",
    "teste_acuracia_otimizado = accuracy_score(y_teste, predicao_teste_otimizado)\n",
    "print(\"Acurácia (modelo inicial):\", teste_acuracia_otimizado)\n",
    "print(\"Relatório de Classificação (modelo inicial):\\n\", classification_report(y_teste, predicao_teste_otimizado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para gerar a matriz de confusão.\n",
    "letras = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"I\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"Y\"]\n",
    "y_prob_teste = mlp_otimizado.predict_proba(x_teste_pca)\n",
    "\n",
    "plotar_matriz_confusao(y_teste, predicao_teste_otimizado, letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_ruidosa = x_teste_pca + np.random.normal(0, 0.1, x_teste_pca.shape)\n",
    "x_teste_ruidosa = np.clip(x_teste_ruidosa, 0, 1)\n",
    "\n",
    "y_pred_ruidosa = mlp_otimizado.predict(x_teste_ruidosa)\n",
    "teste_acuracia_padrao = accuracy_score(y_teste, y_pred_ruidosa)\n",
    "\n",
    "print(\"Acurácia:\", teste_acuracia_padrao)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
