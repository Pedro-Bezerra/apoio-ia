{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados preparados\n",
    "x_treino = np.load('x_treino.npy')  # Carrega as imagens de treinamento\n",
    "y_treino = np.load('y_treino.npy')  # Carrega os rótulos de treinamento\n",
    "z_treino = np.load('z_treino.npy')\n",
    "\n",
    "x_validacao = np.load('x_validacao.npy')  # Carrega as imagens de validação\n",
    "y_validacao = np.load('y_validacao.npy')  # Carrega os rótulos de validação\n",
    "z_validacao = np.load('z_validacao.npy')\n",
    "\n",
    "x_teste = np.load('x_teste.npy')  # Carrega as imagens de teste\n",
    "y_teste = np.load('y_teste.npy')  # Carrega os rótulos de teste\n",
    "z_teste = np.load('z_teste.npy')\n",
    "\n",
    "print(np.shape(x_treino))\n",
    "print(np.shape(x_validacao))\n",
    "print(np.shape(x_teste))\n",
    "print(y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino = x_treino.reshape(-1, 64, 64, 1)\n",
    "x_validacao = x_validacao.reshape(-1, 64, 64, 1)\n",
    "x_teste = x_teste.reshape(-1, 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_mapping = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"I\": 9, \"L\": 12, \"M\": 13, \"N\": 14, \"O\": 15, \"P\": 16, \"Q\": 17, \"R\": 18, \"S\": 19, \"T\": 20, \"U\": 21, \"V\": 22, \"W\": 23, \"Y\": 25}\n",
    "\n",
    "letras_indices = {letra: idx for idx, letra in enumerate(letras_mapping.keys())}\n",
    "y_treino = to_categorical([letras_indices[letra] for letra in y_treino])\n",
    "y_validacao = to_categorical([letras_indices[letra] for letra in y_validacao])\n",
    "y_teste = to_categorical([letras_indices[letra] for letra in y_teste])\n",
    "print(y_treino)\n",
    "print(y_validacao)\n",
    "print(y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(letras_mapping), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = create_cnn_model()\n",
    "history = cnn_model.fit(\n",
    "    x_treino, y_treino,\n",
    "    validation_data=(x_validacao, y_validacao),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(x_teste, y_teste)\n",
    "print(f\"Acurácia no teste: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Erro de Treinamento')\n",
    "plt.plot(history.history['val_loss'], label='Erro de Teste')\n",
    "plt.legend()\n",
    "plt.title('Erro por Época')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')\n",
    "plt.plot(history.history['val_accuracy'], label='Acurácia de Teste')\n",
    "plt.legend()\n",
    "plt.title('Acurácia por Época')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn_model.predict(x_teste).argmax(axis=1)\n",
    "y_true = y_teste.argmax(axis=1)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=letras_mapping.keys())\n",
    "disp.plot(cmap='Blues')\n",
    "plt.xlabel('Rótulos previstos')  \n",
    "plt.ylabel('Rótulos verdadeiros')  \n",
    "plt.title('Matriz de Confusão - CNN Padrão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Conv2D(hp.Int('filters', 32, 128, step=32), (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1)),\n",
    "        Conv2D(hp.Int('filters2', 32, 128, step=32), (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(hp.Int('dense_units', 64, 256, step=64), activation='relu'),\n",
    "        Dropout(hp.Float('dense_dropout', 0.2, 0.5, step=0.1)),\n",
    "        Dense(len(letras_mapping), activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=2,  \n",
    "    directory='my_dir',\n",
    "    project_name='cnn_tuner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_treino, y_treino, validation_data=(x_validacao, y_validacao), epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "print(f\"Melhores Hiperparâmetros: {best_hps.values}\")\n",
    "\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history_optimized = best_model.fit(x_treino, y_treino, validation_data=(x_validacao, y_validacao), epochs=10, batch_size=32)\n",
    "test_loss_optimized, test_acc_optimized = best_model.evaluate(x_teste, y_teste)\n",
    "print(f\"Acurácia otimizada no teste: {test_acc_optimized:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_optimized.history['loss'], label='Erro de Treinamento')\n",
    "plt.plot(history_optimized.history['val_loss'], label='Erro de Teste')\n",
    "plt.legend()\n",
    "plt.title('Erro por Época - Modelo Otimizado')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_optimized.history['accuracy'], label='Acurácia de Treinamento')\n",
    "plt.plot(history_optimized.history['val_accuracy'], label='Acurácia de Teste')\n",
    "plt.legend()\n",
    "plt.title('Acurácia por Época - Modelo Otimizado')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_optimized = best_model.predict(x_teste).argmax(axis=1)\n",
    "conf_matrix_optimized = confusion_matrix(y_true, y_pred_optimized)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix_optimized, display_labels=letras_mapping.keys())\n",
    "disp.plot(cmap='Blues')\n",
    "plt.xlabel('Rótulos previstos')  \n",
    "plt.ylabel('Rótulos verdadeiros')  \n",
    "plt.title('Matriz de Confusão - Modelo Otimizado')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_ruidosa = x_teste + np.random.normal(0, 0.1, x_teste.shape)\n",
    "\n",
    "x_teste_ruidosa = np.clip(x_teste_ruidosa, 0, 1).astype(np.float32)\n",
    "\n",
    "print(\"Forma dos dados ruidosos:\", x_teste_ruidosa.shape)\n",
    "print(y_teste)\n",
    "\n",
    "loss, accuracy = cnn_model.evaluate(x_teste_ruidosa, y_teste)\n",
    "\n",
    "print(\"Acurácia Ruidosa:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_ruidosa = x_teste + np.random.normal(0, 0.1, x_teste.shape)\n",
    "\n",
    "x_teste_ruidosa = np.clip(x_teste_ruidosa, 0, 1).astype(np.float32)\n",
    "\n",
    "\n",
    "print(\"Forma dos dados ruidosos:\", x_teste_ruidosa.shape)\n",
    "print(y_teste)\n",
    "\n",
    "\n",
    "loss, accuracy = best_model.evaluate(x_teste_ruidosa, y_teste)\n",
    "\n",
    "print(\"Acurácia Ruidosa:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
